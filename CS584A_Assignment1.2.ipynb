{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 584 Assignment 1 -- Text Classification (Machine Learning and NLP Basics)\n",
    "\n",
    "#### Name: (Your Name, double click this cell to edit)\n",
    "#### Stevens ID: (Your ID, double click this cell to edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Multi-class Classification (20 Points)\n",
    "\n",
    "## In this assignment, you are required to follow the steps below:\n",
    "1. Review the lecture slides.\n",
    "2. Implement the data loading, preprocessing, tokenization, and TF-IDF feature extraction.\n",
    "3. Implement Logistic Regression model, evaluation metrics, SGD, and Mini-batch GD.\n",
    "4. Implement Cross-validation to choose the best lambda.\n",
    "5. Analysis the results in the Conlusion part.\n",
    "\n",
    "**Before you start**\n",
    "- Please read the code very carefully.\n",
    "- Install these packages (jupyterlab, nltk, numpy, and matplotlib) using the following command.\n",
    "```console\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "- You are **NOT** allowed to use other packages unless otherwise specified.\n",
    "- You are **ONLY** allowed to edit the code between `# Start your code here` and `# End` for each block.\n",
    "- Most of the code can be reused from the Assignment 1.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing\n",
    "\n",
    "* Download the dataset from Canvas\n",
    "* Load data to text and labels\n",
    "* Preprocessing\n",
    "* Tokenization\n",
    "* Split data\n",
    "* Feature extraction (TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download NLTK stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import nltk\n",
    "\n",
    "\n",
    "nltk_path = os.path.join('a1-data', 'nltk')\n",
    "nltk.download('stopwords', download_dir=nltk_path)\n",
    "nltk.data.path.append(nltk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def print_line(*args):\n",
    "    \"\"\" Inline print and go to the begining of line\n",
    "    \"\"\"\n",
    "    args1 = [str(arg) for arg in args]\n",
    "    str_ = ' '.join(args1)\n",
    "    sys.stdout.write(str_ + '\\r')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load data\n",
    "\n",
    "- Load sentences and labels\n",
    "- Transform string labels into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentence_label(data_path: str) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\" Load sentences and labels from the specified path\n",
    "    Args:\n",
    "        data_path: data_path: path to the data file, e.g., 'a1-data/SMSSpamCollection'\n",
    "        sentences: the raw text list of all sentences\n",
    "    Returns:\n",
    "        labels: the label list of all sentences\n",
    "    \"\"\"\n",
    "    sentences, labels = [], []\n",
    "    # Start your code here (load text and label from files)\n",
    "    \n",
    "    # End\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('a1-data', 'books.txt')\n",
    "sentences, labels = load_sentence_label(data_path)\n",
    "\n",
    "label_map = {}\n",
    "for label in sorted(list(set(labels))):\n",
    "    label_map[label] = len(label_map)\n",
    "labels = np.array([label_map[label] for label in labels], dtype=int)\n",
    "sentences = np.array(sentences, dtype=object)\n",
    "\n",
    "print('Label map:', label_map)\n",
    "print('Number of sentences and labels:', len(sentences), len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(sentences: np.ndarray,\n",
    "                     labels: np.ndarray,\n",
    "                     test_ratio: float = 0.2) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\" Split the sentences and labels into training and test data by shuffling\n",
    "    Args:\n",
    "        sentences: A numpy array containing all sentences\n",
    "        labels: A number array containing label ids\n",
    "        test_ratio: A float number to calculate the number of test data\n",
    "\n",
    "    Returns:\n",
    "        train_sentences: A numpy array containing all training sentences\n",
    "        train_labels: A number array containing all training label ids\n",
    "        test_sentences: A numpy array containing all test sentences\n",
    "        test_labels: A number array containing all test label ids\n",
    "    \"\"\"\n",
    "    assert 0 < test_ratio < 1\n",
    "    assert len(sentences) == len(labels)\n",
    "\n",
    "    train_index, test_index = [], []\n",
    "    # Start your code here (split the index for training and test)\n",
    "    \n",
    "    # End\n",
    "\n",
    "    train_sentences, train_labels = sentences[train_index], labels[train_index]\n",
    "    test_sentences, test_labels = sentences[test_index], labels[test_index]\n",
    "    return train_sentences, train_labels, test_sentences, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6666)\n",
    "\n",
    "test_ratio = 0.2\n",
    "valid_ratio = 0.1\n",
    "(train_sentences, train_labels,\n",
    "    test_sentences, test_labels) = train_test_split(sentences, labels, test_ratio)\n",
    "(train_sentences, train_labels,\n",
    "    valid_sentences, valid_labels) = train_test_split(train_sentences, train_labels, valid_ratio)\n",
    "\n",
    "print('Training data length:', len(train_sentences))\n",
    "print('Validation data length:', len(valid_sentences))\n",
    "print('Test data length:', len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_label(labels: np.ndarray, label_map: dict[str, int]) -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        labels: The labels of a dataset \n",
    "        label_map: The mapping from label to label id\n",
    "    Returns:\n",
    "        label_count: The mapping from label to its count\n",
    "    \"\"\"\n",
    "    label_count = {key: 0 for key in label_map.keys()}\n",
    "    # Start your code here (count the number of each label)\n",
    "    \n",
    "    # End\n",
    "    return label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training:', count_label(train_labels, label_map))\n",
    "print('Validation:', count_label(valid_labels, label_map))\n",
    "print('Test:', count_label(test_labels, label_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset statistics\n",
    "Fill this table with the statistics you just printed (double click this cell to edit)\n",
    "\n",
    "|                | Arthur Conan Doyle | Fyodor Dostoyevsky | Jane Austen | Total |\n",
    "|:--------------:|--------------------|--------------------|-------------|-------|\n",
    "|  **Training**  |                    |                    |             |       |\n",
    "| **Validation** |                    |                    |             |       |\n",
    "|    **Test**    |                    |                    |             |       |\n",
    "|    **Total**   |                    |                    |             |       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Preprocess\n",
    "In this section, you need to remove all the unrelated characters, including punctuation, urls, and numbers. Please fill up the functions and test them by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, punctuation=True, url=True, number=True):\n",
    "        self.punctuation = punctuation\n",
    "        self.url = url\n",
    "        self.number = number\n",
    "\n",
    "    def apply(self, sentence: str) -> str:\n",
    "        \"\"\" Apply the preprocessing rules to the sentence\n",
    "        Args:\n",
    "            sentence: raw sentence\n",
    "        Returns:\n",
    "            sentence: clean sentence\n",
    "        \"\"\"\n",
    "        sentence = sentence.lower()\n",
    "        if self.url:\n",
    "            sentence = Preprocessor.remove_url(sentence)\n",
    "        if self.punctuation:\n",
    "            sentence = Preprocessor.remove_punctuation(sentence)\n",
    "        if self.number:\n",
    "            sentence = Preprocessor.remove_number(sentence)\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "        return sentence\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_punctuation(sentence: str) -> str:\n",
    "        \"\"\" Remove punctuations in sentence with re\n",
    "        Args:\n",
    "            sentence: sentence with possible punctuations\n",
    "        Returns:\n",
    "            sentence: sentence without punctuations\n",
    "        \"\"\"\n",
    "        # Start your code here\n",
    "        \n",
    "        # End\n",
    "        return sentence\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_url(sentence: str) -> str:\n",
    "        \"\"\" Remove urls in text with re\n",
    "        Args:\n",
    "            sentence: sentence with possible urls\n",
    "        Returns:\n",
    "            sentence: sentence without urls\n",
    "        \"\"\"\n",
    "        # Start your code here\n",
    "        \n",
    "        # End\n",
    "        return sentence\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_number(sentence: str) -> str:\n",
    "        \"\"\" Remove numbers in sentence with re\n",
    "        Args:\n",
    "            sentence: sentence with possible numbers\n",
    "        Returns:\n",
    "            sentence: sentence without numbers\n",
    "        \"\"\"\n",
    "        # Start your code here\n",
    "        \n",
    "        # End\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test your implementation by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Interest rates are trimmed to 7.5 by the South African central bank (https://www.xxx.xxx), but the lack of warning hits the rand and surprises markets.\"\n",
    "\n",
    "processor = Preprocessor()\n",
    "clean_sentence = processor.apply(sentence)\n",
    "\n",
    "print(f'\"{sentence}\"') \n",
    "print('===>')\n",
    "print(f'\"{clean_sentence}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "print(list(stopwords_set)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence: str) -> List[str]:\n",
    "    \"\"\" Tokenize a sentence into tokens (words)\n",
    "    Args:\n",
    "        sentence: clean sentence\n",
    "    Returns:\n",
    "        tokens\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    # Start your code here\n",
    "    #     Step 1. Split sentence into words\n",
    "    #     Step 2. Extract word stem using the defined stemmer (PorterStemmer) by calling stemmer.stem(word)\n",
    "    #     Step 3. Remove stop words using the defined stopwords_set\n",
    "    \n",
    "    # End\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test your implementation by running the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Interest rates are trimmed to 7.5 by the South African central bank (https://www.xxx.xxx), but the lack of warning hits the rand and surprises markets.\"\n",
    "\n",
    "processor = Preprocessor()\n",
    "clean_sentence = processor.apply(sentence)\n",
    "tokens = tokenize(clean_sentence)\n",
    "\n",
    "print(f'\"{sentence}\"') \n",
    "print('===>')\n",
    "print(f'\"{tokens}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Feature Extraction\n",
    "\n",
    "TF-IDF:\n",
    "$$\\text{TF-IDF}(t, d) = \\frac{f_{t, d}}{\\sum_{t'}{f_{t', d}}} \\times \\log{\\frac{N}{n_t}}$$\n",
    "\n",
    "- $t$: A term\n",
    "- $d$: A document. Here, we regard a sentence as a document\n",
    "- $f_{t, d}$: Number of term $t$ in $d$\n",
    "- $N$: Number of document\n",
    "- $n_t$: Number of document containing $t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class TfIdfEncoder:\n",
    "    def __init__(self):\n",
    "        self.vocab = defaultdict(int)\n",
    "        self.token2index = {}\n",
    "        self.df = defaultdict(int)\n",
    "        self.num_doc = 0\n",
    "        self.processor = Preprocessor()\n",
    "\n",
    "    def fit(self, sentences: Union[List[str], np.ndarray]) -> int:\n",
    "        \"\"\" Using the given texts to store key information in TF-IDF calculation\n",
    "            In this function, you are required to implement the fitting process.\n",
    "                1. Construct the vocabulary and store the frequency of tokens (self.vocab).\n",
    "                2. Construct the document frequency map to tokens (self.df).\n",
    "                3. Construct the token to index map based on the frequency.\n",
    "                   The token with a higher frequency has the smaller index\n",
    "        Args:\n",
    "            sentences: Raw sentences\n",
    "        Returns:\n",
    "            token_num\n",
    "        \"\"\"\n",
    "        self.num_doc = len(sentences)\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            if i % 100 == 0 or i == len(sentences) - 1:\n",
    "                print_line('Fitting TF-IDF encoder:', (i + 1), '/', len(sentences))\n",
    "            # Start your code here (step 1 & 2)\n",
    "            \n",
    "            # End\n",
    "        print_line('\\n')\n",
    "        # Start your code here (Step 3)\n",
    "        \n",
    "        # End\n",
    "        token_num = len(self.token2index) \n",
    "        print('The number of distinct tokens:', token_num)\n",
    "        return token_num\n",
    "\n",
    "    def encode(self, sentences: Union[List[str], np.ndarray]) -> np.ndarray:\n",
    "        \"\"\" Encode the sentences into TF-IDF feature vector\n",
    "            Note: if a token in a sentence does not exist in the fit encoder, we just ignore it.\n",
    "        Args:\n",
    "            sentences: Raw sentences\n",
    "        Returns:\n",
    "            features: A (n x token_num) matrix, where n is the number of sentences\n",
    "        \"\"\"\n",
    "        n = len(sentences)\n",
    "        features = np.zeros((n, len(self.token2index)))\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            if i % 100 == 0 or i == n - 1:\n",
    "                print_line('Encoding with TF-IDF encoder:', (i + 1), '/', n)\n",
    "            # Start your code (calculate TF-IDF)\n",
    "            \n",
    "            # End\n",
    "        print_line('\\n')\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test your implementation by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TfIdfEncoder()\n",
    "encoder.fit(train_sentences[:100])\n",
    "features = encoder.encode(train_sentences[:10])\n",
    "\n",
    "print(features[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode training, validation, and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 3\n",
    "\n",
    "encoder = TfIdfEncoder()\n",
    "vocab_size = encoder.fit(train_sentences)\n",
    "\n",
    "x_train = encoder.encode(train_sentences)\n",
    "x_valid = encoder.encode(valid_sentences)\n",
    "x_test = encoder.encode(test_sentences)\n",
    "\n",
    "y_train = np.zeros((len(train_labels), num_class))\n",
    "y_valid = np.zeros((len(valid_labels), num_class))\n",
    "y_test = np.zeros((len(test_labels), num_class))\n",
    "y_train[np.arange(len(train_labels)), train_labels] = 1\n",
    "y_valid[np.arange(len(valid_labels)), valid_labels] = 1\n",
    "y_test[np.arange(len(test_labels)), test_labels] = 1\n",
    "\n",
    "print('The size of training set:', x_train.shape, y_train.shape)\n",
    "print('The size of validation set:', x_valid.shape, y_valid.shape)\n",
    "print('The size of test set:', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression\n",
    "In this section, you are required to implement a Logistic Regression (LR) model with $L_2$ regularization from scratch. \n",
    "\n",
    "The objective function of LR for binary classification:\n",
    "\n",
    "$$J = L(\\mathbf{x}, \\mathbf{y} \\mid \\mathbf{w}, \\mathbf{b}) = -\\frac{1}{n}\\sum_{i=1}^{N}\\sum_{k=1}^{K}y_{ik}log\\frac{e^{f_k}}{\\sum_{c=1}^{K}e^{f_c}} + \\lambda \\sum_{j=1}^{d}w_{kj}^2$$\n",
    "\n",
    "- $\\hat{\\mathbf{y}} = \\text{Softmax}(\\mathbf{x}\\mathbf{w} + \\mathbf{b})$\n",
    "- $n$: Number of samples\n",
    "- $d$: Dimension of $\\mathbf{w}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: np.ndarray, axis: int = -1) -> np.ndarray:\n",
    "    \"\"\" The softmax activation function\n",
    "    Args:\n",
    "        x: Input matrix or vector\n",
    "        axis: The dimension of x that needs to run softmax, default -1, i.e., the last dimension\n",
    "    Returns:\n",
    "        output: Softmax value of the specified dimension in x\n",
    "    \"\"\"\n",
    "    # Start your code here\n",
    "    \n",
    "    # End\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, feature_dim: int, num_class: int, lambda_: float):\n",
    "        \"\"\" Logistic Regression Model\n",
    "        Args:\n",
    "            feature_dim: feature dimension\n",
    "            num_class: number of class\n",
    "            lambda_: lambda in L2 regularizer\n",
    "        \"\"\"\n",
    "        # Start your code here (initialize weight and bias)\n",
    "        # self.w =\n",
    "        # self.b =\n",
    "        \n",
    "        # End\n",
    "        self.lambda_ = lambda_\n",
    "        self.eps = 1e-9\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Forward process of logistic regression\n",
    "            Calculate y_hat using x\n",
    "        Args:\n",
    "            x: Input data\n",
    "        Returns:\n",
    "            y_hat: Output\n",
    "        \"\"\"\n",
    "        y_hat = 0\n",
    "        # Start your code here (calculate y_hat of logistic regression using x)\n",
    "        \n",
    "        # End\n",
    "        return y_hat\n",
    "\n",
    "    def backward(self,\n",
    "                 x: np.ndarray,\n",
    "                 y_hat: np.ndarray,\n",
    "                 y: np.ndarray) -> Tuple[np.ndarray, Union[float, np.ndarray]]:\n",
    "        \"\"\" Backward process of logistic regression\n",
    "            Calculate the gradient of w and b\n",
    "        Args:\n",
    "            x: Input data\n",
    "            y_hat: Output of forward\n",
    "            y: Ground-truth\n",
    "        Returns:\n",
    "            w_grad: Gradient of w\n",
    "            b_grad: Gradient of b\n",
    "        \"\"\"\n",
    "        w_grad, b_grad = 0.0, 0.0\n",
    "        n = len(x)\n",
    "        # Start your code here (calculate the gradient of w and b)\n",
    "        \n",
    "        # End\n",
    "        return w_grad, b_grad\n",
    "\n",
    "    def categorical_cross_entropy_loss(self,\n",
    "                                       y_hat: np.ndarray,\n",
    "                                       y: np.ndarray) -> Union[float, np.ndarray]:\n",
    "        \"\"\" Calculate the binary cross-entropy loss\n",
    "        Args:\n",
    "            y_hat: Output of forward\n",
    "            y: Ground-truth\n",
    "        Returns:\n",
    "            loss: BCE loss\n",
    "        \"\"\"\n",
    "        y_hat = np.clip(y_hat, a_min=self.eps, a_max=1 - self.eps)\n",
    "        loss = 0\n",
    "        # Start your code here (Calculate the binary cross-entropy)\n",
    "        \n",
    "        # End\n",
    "        return loss\n",
    "\n",
    "    def gradient_descent(self, w_grad: np.ndarray, b_grad: Union[np.ndarray, float], lr: float):\n",
    "        self.w -= lr * w_grad\n",
    "        self.b -= lr * b_grad\n",
    "\n",
    "    def predict(self, y_hat: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Predict the label using the output y_hat\n",
    "        Args:\n",
    "            y_hat: Model output\n",
    "        Returns:\n",
    "            pred: Prediction\n",
    "        \"\"\"\n",
    "        pred = np.zeros_like(y_hat)\n",
    "        index = np.argmax(y_hat, axis=-1)\n",
    "        pred[np.arange(len(y_hat)), index] = 1\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Evaluation Metrics\n",
    "\n",
    "Accuracy, Precision, Recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def get_metrics(y_pred: np.ndarray, y_true: np.ndarray) -> Tuple[float, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\" Calculate the accuracy, precision, recall, and f1 score.\n",
    "        You are allowed to use precision_recall_fscore_support from scikit-learn. Please set average to 'micro'\n",
    "    Args:\n",
    "        y_pred: Prediction\n",
    "        y_true: Ground-truth\n",
    "    Returns:\n",
    "        accuracy: float number. The accuracy for the whole dataset\n",
    "        precision, recall, f1: np.ndarray (num_class, ). The precision, recall, f1 for each class\n",
    "    \"\"\"\n",
    "    assert y_pred.shape == y_true.shape\n",
    "    accuracy, precision, recall, f1 = 0.0, 0.0, 0.0, 0.0\n",
    "    # Start your code here\n",
    "    \n",
    "    # End\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def train_sgd(model: 'LogisticRegression',\n",
    "              x_train: np.ndarray,\n",
    "              y_train: np.ndarray,\n",
    "              x_valid: np.ndarray,\n",
    "              y_valid: np.ndarray,\n",
    "              lr: float,\n",
    "              num_epoch: int,\n",
    "              print_every: int = 10) -> Tuple[dict[str, List], dict[str, List]]:\n",
    "    \"\"\" Training with Stochastic Gradient Descent\n",
    "    Args:\n",
    "        model: The logistic regression model\n",
    "        x_train: Training feature, (n x d) matrix\n",
    "        y_train: Training label, (n, ) vector\n",
    "        x_valid: Validation feature, (n x d) matrix\n",
    "        y_valid: Validation label, (n, ) vector\n",
    "        lr: Learning rate\n",
    "        num_epoch: Number of training epochs\n",
    "        print_every: Print log every {print_every} epochs\n",
    "    Returns:\n",
    "        train_history: Log of training information. The format of training history is\n",
    "                       { 'loss': [] }\n",
    "                       It records the average loss of each epoch.\n",
    "        valid_history: Log of validation information. The format of validation history is\n",
    "                       {\n",
    "                           'loss': [],\n",
    "                           'accuracy': [],\n",
    "                           'precision': [],\n",
    "                           'recall': [],\n",
    "                           'f1': []\n",
    "                       }\n",
    "    \"\"\"\n",
    "    train_history = OrderedDict({'loss': []})\n",
    "    valid_history = OrderedDict({\n",
    "        'loss': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': []\n",
    "    })\n",
    "\n",
    "    def format_output(epoch, num_epoch, train_history, valid_history):\n",
    "        epoch_log = f'Epoch {epoch + 1} / {num_epoch}'\n",
    "        train_log = ' - '.join([f'train_{key}: {val[-1]:.4f}' for key, val in train_history.items()])\n",
    "        valid_log = ' - '.join([f'valid_{key}: {val[-1]:.4f}' for key, val in valid_history.items()])\n",
    "        log = f'{epoch_log}: {train_log} - {valid_log}'\n",
    "        return log\n",
    "\n",
    "    train_num_samples = len(x_train)\n",
    "    for epoch in range(num_epoch):\n",
    "        epoch_loss = 0.0\n",
    "        # Start your code here (training)\n",
    "        #     Step 1. Model forward\n",
    "        #     Step 2. Calculate loss\n",
    "        #     Step 3. Model backward\n",
    "        #     Step 4. Optimization with gradient descent\n",
    "        \n",
    "        # End\n",
    "\n",
    "        valid_loss = 0.\n",
    "        accuracy, precision, recall, f1 = 0.0, 0.0, 0.0, 0.0\n",
    "        # Start your code here (validation)\n",
    "        #     Step 1. Predict\n",
    "        #     Step 2. Calculate loss\n",
    "        #     Step 3. Calculate metrics\n",
    "        \n",
    "        # End\n",
    "\n",
    "        train_history['loss'].append(epoch_loss / train_num_samples)\n",
    "        for vals, val in zip(valid_history.values(), [valid_loss, accuracy, precision, recall, f1]):\n",
    "            vals.append(val)\n",
    "        log = format_output(epoch, num_epoch, train_history, valid_history)\n",
    "        if epoch % print_every == 0 or epoch == num_epoch - 1:\n",
    "            print(log)\n",
    "        else:\n",
    "            print_line(log)\n",
    "\n",
    "    return train_history, valid_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6666)\n",
    "\n",
    "num_epoch = 100\n",
    "lr = 1e-1\n",
    "lambda_ = 1e-7\n",
    "print_every = 10\n",
    "\n",
    "model_sgd = LogisticRegression(feature_dim=vocab_size, num_class=num_class, lambda_=lambda_)\n",
    "sgd_train_history, sgd_valid_history = train_sgd(model_sgd, x_train, y_train, x_valid, y_valid, lr, num_epoch, print_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mbgd(model: 'LogisticRegression',\n",
    "               x_train: np.ndarray,\n",
    "               y_train: np.ndarray,\n",
    "               x_valid: np.ndarray,\n",
    "               y_valid: np.ndarray,\n",
    "               lr: float,\n",
    "               num_epoch: int,\n",
    "               batch_size: int,\n",
    "               print_every: int = 10) -> Tuple[dict[str, List], dict[str, List]]:\n",
    "    \"\"\" Training with Stochastic Gradient Descent\n",
    "    Args:\n",
    "        model: The logistic regression model\n",
    "        x_train: Training feature, (n x d) matrix\n",
    "        y_train: Training label, (n, ) vector\n",
    "        x_valid: Validation feature, (n x d) matrix\n",
    "        y_valid: Validation label, (n, ) vector\n",
    "        lr: Learning rate\n",
    "        num_epoch: Number of training epochs\n",
    "        batch_size: Number of training samples in a batch\n",
    "        print_every: Print log every {print_every} epochs\n",
    "    Returns:\n",
    "        train_history: Log of training information. The format of training history is\n",
    "                       { 'loss': [] }\n",
    "                       It records the average loss of each epoch.\n",
    "        valid_history: Log of validation information. The format of training and validation history is\n",
    "                       {\n",
    "                           'loss': [],\n",
    "                           'accuracy': [],\n",
    "                           'precision': [],\n",
    "                           'recall': [],\n",
    "                           'f1': []\n",
    "                       }\n",
    "    \"\"\"\n",
    "    train_history = OrderedDict({'loss': []})\n",
    "    valid_history = OrderedDict({\n",
    "        'loss': [],\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1': []\n",
    "    })\n",
    "\n",
    "    def format_output(epoch, num_epoch, train_history, valid_history):\n",
    "        epoch_log = f'Epoch {epoch + 1} / {num_epoch}'\n",
    "        train_log = ' - '.join([f'train_{key}: {val[-1]:.4f}' for key, val in train_history.items()])\n",
    "        valid_log = ' - '.join([f'valid_{key}: {val[-1]:.4f}' for key, val in valid_history.items()])\n",
    "        log = f'{epoch_log}: {train_log} - {valid_log}'\n",
    "        return log\n",
    "\n",
    "    train_num_samples = len(x_train)\n",
    "    n_batch = train_num_samples // batch_size\n",
    "    for epoch in range(num_epoch):\n",
    "        epoch_loss = 0.0\n",
    "        # Start your code here (training)\n",
    "        #     Step 1. Model forward\n",
    "        #     Step 2. Calculate loss\n",
    "        #     Step 3. Model backward\n",
    "        #     Step 4. Optimization with gradient descent\n",
    "        \n",
    "        # End\n",
    "\n",
    "        valid_loss = 0.\n",
    "        accuracy, precision, recall, f1 = 0.0, 0.0, 0.0, 0.0\n",
    "        # Start your code here (validation)\n",
    "        #     Step 1. Predict\n",
    "        #     Step 2. Calculate loss\n",
    "        #     Step 3. Calculate metrics\n",
    "        \n",
    "        # End\n",
    "\n",
    "        train_history['loss'].append(epoch_loss / train_num_samples)\n",
    "        for vals, val in zip(valid_history.values(), [valid_loss, accuracy, precision, recall, f1]):\n",
    "            vals.append(val)\n",
    "        log = format_output(epoch, num_epoch, train_history, valid_history)\n",
    "        if epoch % print_every == 0 or epoch == num_epoch - 1:\n",
    "            print(log)\n",
    "        else:\n",
    "            print_line(log)\n",
    "\n",
    "    return train_history, valid_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6666)\n",
    "\n",
    "num_epoch = 100\n",
    "lr = 1e-1\n",
    "batch_size = 4\n",
    "lambda_ = 1e-7\n",
    "print_every = 10\n",
    "\n",
    "model_mbgd = LogisticRegression(feature_dim=vocab_size, num_class=num_class, lambda_=lambda_)\n",
    "mbgd_train_history, mbgd_valid_history = train_mbgd(model_mbgd, x_train, y_train, x_valid, y_valid, lr, num_epoch, batch_size, print_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Evaluation\n",
    "You are required to report the loss, accuracy, precision, recall, and f1 on test set and plot the the curve of them for both SGD and Mini-batch GD on train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start your code here\n",
    "# Calculate the metrics for test set and fill in the table below\n",
    "# SGD\n",
    "\n",
    "# Mini-batch GD\n",
    "\n",
    "# End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics on Test set\n",
    "Fill this table with the result you just printed (double click this cell to edit)\n",
    "|     Optimizer     | Accuracy    | Precision   | Recall      | F1 Score    |\n",
    "|:-----------------:|-------------|-------------|-------------|-------------|\n",
    "|      **SGD**      |             |             |             |             |\n",
    "| **Mini-batch GD** |             |             |             |             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Please run the following cell to plot the training loss curve for SGD and Mini-batch GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(4, 3))\n",
    "plt.plot(sgd_train_history['loss'], label='SGD')\n",
    "plt.plot(mbgd_train_history['loss'], label='Mini-batch GD')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Please run the following cell to plot the validation metrics curve for SGD and Mini-batch GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(20, 3))\n",
    "for i, key in enumerate(sgd_valid_history.keys()):\n",
    "    sgd_vals, mbgd_vals = sgd_valid_history[key], mbgd_valid_history[key]\n",
    "    ax = axes[i]\n",
    "    ax.plot(sgd_vals, label='SGD')\n",
    "    ax.plot(mbgd_vals, label='Mini-batch GD')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_title('Validation ' + key.capitalize())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-Validation\n",
    "\n",
    "You are required to use cross-validation to choose the best $\\lambda$ with Mini-batch GD.\n",
    "\n",
    "The best $\\lambda$ should be chosen by monitoring validation $F_1$ score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lambda = 0.0\n",
    "best_f1 = 0.0\n",
    "\n",
    "num_epoch = 100\n",
    "lr = 1e-1\n",
    "batch_size = 4\n",
    "print_every = 100\n",
    "# Start your code here\n",
    "#     Step 1. Iterate all lambdas\n",
    "#     Step 2. set the random seed and run train_mbgd for every lambda\n",
    "#     Step 3. Choose the best lambda\n",
    "\n",
    "# End\n",
    "print(best_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report the best $\\lambda$ value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion\n",
    "\n",
    "Provide an analysis for all the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
